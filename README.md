# comp-ds
Life is too short to describe repo in readme, but let's add some basics

[qm]-question-mark answer questions
[pr]-practice 

# Competitive Data Science Notes

This repository contains a collection of notebooks, code snippets, and tools focused on practical techniques used in competitive data science. It covers core topics such as feature engineering, model tuning, cross-validation, and deployment strategies for machine learning projects.

## Key Topics

- **Feature Engineering** – Techniques for creating, transforming, and selecting meaningful features
- **Model Tuning** – Hyperparameter optimization using grid search and random search
- **Cross-Validation** – Methods to improve model validation and selection
- **Ensemble Methods** – Building robust models using ensemble techniques like stacking and boosting
- **Data Preprocessing** – Handling missing values, encoding, scaling, and text data processing

## Repository Structure

- [`notebooks/`](./notebooks) – Jupyter notebooks for hands-on learning and experimentation
- [`src/`](./src) – Reusable code modules for data processing, model training, and evaluation
- [`utils/`](./utils) – Helper utilities for common data science tasks
- [`subs/`](./subs) – Submission scripts and results for various competitions
- [`imgs/`](./imgs) – Visualizations, charts, and diagrams that support analysis
- [`catboost_info/`](./catboost_info) – Detailed experiments and insights into using CatBoost
- [`others/`](./others) – Miscellaneous tools and resources for various tasks

## Toolkit

The repository includes code and examples for:

- **CatBoost** for gradient boosting and working with categorical data
- **XGBoost** and **LightGBM** for efficient tree-based models
- **Scikit-learn** for traditional machine learning models
- **Pandas** and **NumPy** for data manipulation and analysis

## Installation

To set up the environment, install the required dependencies using the following command:

```bash
pip install -r requirements.txt
```